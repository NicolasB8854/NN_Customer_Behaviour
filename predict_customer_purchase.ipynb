{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Demo: Predict Customer Purchase Behavior\n",
    "This demo shall introduce the class to the programatic implementation of artificial neural networks. <br>\n",
    "It uses the Predict Customer Purchase Behavior Dataset from Kaggle (https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset), which provides information about customers and their purchase behaviour on a fictional shopping website. <br>\n",
    "The goal of this demo is to train a neural network on the provided data to enable it to predict whether a customer will purchase an item on the website or not, based on his previous interaction with the website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation \n",
    "Here, we want to import all the necessary modules that are used in the demo. <br>\n",
    "We will build the neural network using scikit-learn. <br>\n",
    "Pandas is used for handling and manipulating the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Investigating the Data\n",
    "Next, we will load the data and explore its content using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Dataset\n",
    "file_path = 'customer_purchase_data.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Exploratory Data Analysis (EDA)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset has 9 columns. Those will be called __features__ from now on. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are:\n",
    "- Age: Customer's age\n",
    "- Gender: Customer's gender (0: Male, 1: Female)\n",
    "- Annual Income: Annual income of the customer in dollars\n",
    "- Number of Purchases: Total number of purchases made by the customer\n",
    "- Product Category: Category of the purchased product (0: Electronics, 1: Clothing, 2: Home Goods, 3: Beauty, 4: Sports)\n",
    "- Time Spent on Website: Time spent by the customer on the website in minutes\n",
    "- Loyalty Program: Whether the customer is a member of the loyalty program (0: No, 1: Yes)\n",
    "- Discounts Availed: Number of discounts availed by the customer (range: 0-5)\n",
    "- PurchaseStatus (Target Variable): Likelihood of the customer making a purchase (0: No, 1: Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PurchaseStatus is the column that we want to train our neural network on. \n",
    "The distribution of records within the dataset is as following:\n",
    "- 0 (No Purchase): 48%\n",
    "- 1 (Purchase): 52%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Dataset\n",
    "In this step, we will define our features and prepare them to be used for the neural network. This includes scaling the data and splitting it into training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features (X) and Target (y)\n",
    "X = data.drop('PurchaseStatus', axis=1)  # Use all features except our target variable PurchaseStatus\n",
    "y = data['PurchaseStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating the Model\n",
    "Next, we will train the model on our data using the __MLPClassifier__ class from scikit-learn and evaluate its performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build and Train the Neural Network\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam', max_iter=200, random_state=42)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate the Model\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing the Neural Network with Custom Data\n",
    "Finally, we will create our own set of features to test the performance of the neural network and investigate the impact of the features on the output of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create a Custom Row for Prediction\n",
    "custom_row = {\n",
    "    'Age': 1.5,  \n",
    "    'Gender': 1,  \n",
    "    'AnnualIncome': 42300.76,   \n",
    "    'NumberOfPurchases': 20,  \n",
    "    'ProductCategory': 4, \n",
    "    'TimeSpentOnWebsite': 32.45,  \n",
    "    'LoyaltyProgram': 1, \n",
    "    'DiscountsAvailed': 4,  \n",
    "}\n",
    "\n",
    "# Convert custom row to DataFrame\n",
    "custom_row_df = pd.DataFrame([custom_row])\n",
    "\n",
    "# Scale custom row\n",
    "custom_row_scaled = scaler.transform(custom_row_df)\n",
    "\n",
    "# Predict with the model\n",
    "custom_prediction = mlp.predict(custom_row_scaled)\n",
    "print(f\"Prediction for custom row: {custom_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
